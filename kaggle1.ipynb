{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bcbe8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e3d3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_pickle(\"D:\\gitrep\\DMlab2\\DM2022-Lab2-Master-main\\kaggle\\\\trdata_withlabel.pkl\")\n",
    "test_data=pd.read_pickle(\"D:\\gitrep\\DMlab2\\DM2022-Lab2-Master-main\\kaggle\\\\test_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f8983d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>7989</td>\n",
       "      <td>7989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anticipation</th>\n",
       "      <td>50041</td>\n",
       "      <td>50041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>27603</td>\n",
       "      <td>27603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>12746</td>\n",
       "      <td>12746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>103165</td>\n",
       "      <td>103165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>38504</td>\n",
       "      <td>38504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>9850</td>\n",
       "      <td>9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>41215</td>\n",
       "      <td>41215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id    text\n",
       "emotion                       \n",
       "anger             7989    7989\n",
       "anticipation     50041   50041\n",
       "disgust          27603   27603\n",
       "fear             12746   12746\n",
       "joy             103165  103165\n",
       "sadness          38504   38504\n",
       "surprise          9850    9850\n",
       "trust            41215   41215"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,val=train_test_split(train_data,test_size=0.2)\n",
    "train.groupby(['emotion']).count()\n",
    "val.groupby(['emotion']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e623770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\楊智均\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize)\n",
    "#\n",
    "#train data\n",
    "BOW_500.fit(train.text)\n",
    "x_train_BOW=BOW_500.transform(train.text)\n",
    "#\n",
    "y_train=train['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val data\n",
    "x_val_BOW=BOW_500.fit_transform(val.text)\n",
    "#\n",
    "y_val=val['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "BOW_500.fit(test_data.text)\n",
    "x_test_BOW=BOW_500.transform(test_data.text)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f868a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print( label_encoder.classes_)\n",
    "\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linearmodel\n",
    "li_model=linear_model.LinearRegression()\n",
    "li_model=li_model.fit(x_train_BOW,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40073c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "li_pre=li_model.predict(x_test_BOW)\n",
    "li_pre = label_decode(label_encoder, li_pre)\n",
    "output3= pd.DataFrame({'id':test_data.tweet_id , 'emotion': li_pre})\n",
    "output3.to_csv('li_pre.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b49e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model_BOW = DecisionTreeClassifier(random_state=0)\n",
    "dt_model_BOW=dt_model_BOW.fit(x_train_BOW,y_train)\n",
    "#train_pred_BOW = dt_model_BOW.predict(x_train_BOW)\n",
    "test_pred_BOW = dt_model_BOW.predict(x_test_BOW)\n",
    "test_pred_BOW = label_decode(label_encoder, test_pred_BOW)\n",
    "output1 = pd.DataFrame({'id':test_data.tweet_id , 'emotion': test_pred_BOW})\n",
    "output1.to_csv('DT_BOW.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_500 = TfidfVectorizer(max_features=500, tokenizer=nltk.word_tokenize)\n",
    "x_train_TFIDF=TFIDF_500.fit_transform(train.text)\n",
    "#x_val_TFIDF=TFIDF_500.fit_transform(val.text)\n",
    "dt_model_TFIDF = DecisionTreeClassifier(random_state=0)\n",
    "x_test_TFIDF=TFIDF_500.fit_transform(test_data.text)\n",
    "dt_model_TFID=dt_model_TFIDF.fit(x_train_TFIDF,y_train)\n",
    "test_pred_TFIDF = dt_model_TFIDF.predict(x_test_TFIDF)\n",
    "test_pred_TFIDF = label_decode(label_encoder, test_pred_TFIDF)\n",
    "output2 = pd.DataFrame({'id':test_data.tweet_id , 'emotion': test_pred_BOW})\n",
    "output2.to_csv('DT_TFIDF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f2159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = pd.DataFrame({'id':test_data.tweet_id , 'emotion': test_pred_BOW})\n",
    "output2.to_csv('DT_TFIDF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7eee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg_model=LogisticRegression(C=1000, penalty=\"l2\")\n",
    "t_pre=label_decode(label_encoder,y_train)\n",
    "lg_model_BOW=lg_model.fit(x_train_BOW,t_pre)\n",
    "\n",
    "test_pre=lg_model_BOW.predict(x_test_BOW)\n",
    "\n",
    "output4=pd.DataFrame({'id':test_data.tweet_id , 'emotion': test_pre})\n",
    "output4.to_csv('ldpre.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebdd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN_model = MLPClassifier(activation='tanh', solver='sgd', max_iter=100,\n",
    "                             hidden_layer_sizes=(256,64,16), random_state=None, verbose=True,\n",
    "                             early_stopping=False, tol=0.0001)\n",
    "    \n",
    "    # Training \n",
    "NN_model = NN_model.fit(x_train_BOW, y_train)\n",
    "    \n",
    "    # Testing\n",
    "y_train_pred = NN_model.predict(x_train_BOW)\n",
    "y_test_pred = NN_model.predict(x_test_BOW)\n",
    "y_test_pred=label_decode(label_encoder,y_test_pred)    \n",
    "output4=pd.DataFrame({'id':test_data.tweet_id , 'emotion': y_test_pred})\n",
    "output4.to_csv('mlp.csv', index=False)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_500.get_feature_names_out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa0a6943e76f45faea35aad27bbd0e5d1a33a9ac80a51f9d7c3a1d90573781f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
